---
title: "08 - M√°s que One-Hot: encoding inteligente y fairness en Adult Income"
date: 2025-10-21
---

# üß† M√°s que One-Hot: encoding inteligente y fairness en Adult Income

## Contexto
En esta pr√°ctica trabaj√© con el dataset **Adult Income (UCI)** para evaluar **m√©todos de encoding de variables categ√≥ricas** (Label, One-Hot, Target y un **pipeline mixto** con `ColumnTransformer`). Adem√°s, incorpor√© una secci√≥n de **fairness** para juntar encoding, rendimiento y equidad.  
El foco estuvo en **comparar rendimiento, dimensionalidad, tiempo de entrenamiento y explicabilidad**, evitando **data leakage** en t√©cnicas sensibles como Target/LOO.

---

## Objetivos
- Analizar cardinalidad y clasificar variables categ√≥ricas
- Implementar m√∫ltiples t√©cnicas de encoding (label, one-hot, target)
- Prevenir data leakage usando cross-validation en target encoding
- Crear pipelines con branching usando ColumnTransformer
- Comparar m√©todos con m√©tricas cuantitativas
- Evaluar trade-offs entre accuracy, dimensionalidad y tiempo
- Aplicar t√©cnicas avanzadas (smoothing, frequency encoding, ordinal)

---

## Actividades (con tiempos estimados)
- Revisi√≥n del dataset con limpieza y target binario ‚Äî 25 min  
- An√°lisis de cardinalidad y viabilidad de One-Hot ‚Äî 20 min  
- Experimentos de encoding (Label/One-Hot/Target/Pipeline) ‚Äî 60 min  
- Comparativa global + visualizaciones ‚Äî 35 min  
- Explicabilidad (feature importance) ‚Äî 25 min  
- Investigaci√≥n libre (Freq/Ordinal/LOO/Binary/Smoothing) ‚Äî 45 min  
- Reflexi√≥n, documentaci√≥n y armado del portfolio ‚Äî 40 min  

---

## Desarrollo

### Dataset y preprocesamiento
- **Adult Income** (UCI). Target: `income > 50K` ‚Üí `target` (1/0).  
- 32.561 filas, 16 columnas; 8 categ√≥ricas y 6 num√©ricas.  
- Distribuci√≥n del target: ~**24.1%** positivos.

### Cardinalidad y riesgo de explosi√≥n dimensional
- Baja: `workclass`, `marital-status`, `relationship`, `race`, `sex`  
- Media: `education`, `occupation`, `native-country` (42 pa√≠ses)  
- One-Hot total ‚Üí ~**94 columnas** (explosi√≥n ‚âà 11.8√ó). Se limita a baja cardinalidad.

![Barras de cardinalidad por variable categ√≥rica](../assets/ent8_prac9_figA1_barras_cardinalidad.png){ width="800" }

---

## Evidencias

- [Notebook completo](../recursos_files/nueve.ipynb)

### 1) Experimentos de encoding

#### 1.1 Label Encoding
- Funciona muy bien con **√°rboles**.  
- **Resultados**: Accuracy **0.8632**, AUC **0.9101**, F1 **0.6931**, **14 features**.

#### 1.2 One-Hot (solo baja cardinalidad)
- Evita explosi√≥n completa, pero **duplica** columnas vs Label.  
- **Resultados**: Accuracy 0.8483, AUC 0.8995, F1 0.6633, **30 features**.

#### 1.3 Target Encoding (alta cardinalidad)
- Compacto y expresivo; **cuidado con leakage** (fit solo en train / CV).  
- **Resultados**: Accuracy 0.8021, AUC 0.8272, F1 0.5538, **6 features**.

#### 1.4 Pipeline mixto (`ColumnTransformer`)
- Ramas: One-Hot (low-card) + Target (high-card) + Scaling (num).  
- **Resultados**: Accuracy 0.8485, AUC 0.8996, F1 0.6646, **30 features**.


**Tabla comparativa (resumen)**

| Encoding                 | Accuracy |   AUC  |   F1   | Time (s) | Features |
|-------------------------|---------:|------:|------:|---------:|---------:|
| **Label Encoding**      |  0.8632  | 0.9101 | 0.6931 |   0.45   |    14    |
| One-Hot (low card)      |  0.8483  | 0.8995 | 0.6633 |   0.43   |    30    |
| Target (high card)      |  0.8021  | 0.8272 | 0.5538 | **0.43** | **6**    |
| Pipeline (mixto)        |  0.8485  | 0.8996 | 0.6646 |   0.44   |    30    |


**Conclusiones r√°pidas**  
- **Rendimiento puro**: gana **Label** (mejor Accuracy/AUC/F1).  
- **Compacidad**: gana **Target** (6 features).  
- **Producci√≥n**: **Pipeline** ofrece modularidad, control de leakage y mantenibilidad.

---

### 2) Explicabilidad (Feature Importance, Random Forest)

Top importancias (ejemplo t√≠pico):
- `fnlwgt`, `age`, `education-num`, `capital-gain`, `hours-per-week`, y categor√≠as de `marital-status`.

![Barras horizontales de importancia](../assets/ent8_prac9_C1_barras_importancia.png){ width="800" }


![Barras de cardinalidad por variable categ√≥rica y m√©todo](../assets/ent8_prac9_C1_barras_importancia_por_metodos.png){ width="800" }

**Lecturas clave**  
- ~**76%** de la importancia total proviene de **num√©ricas**; **24%** de **categ√≥ricas**.  
- One-Hot capta bien efectos principales; Target/Label ayudan con alta/mezcla de cardinalidades.

---

## An√°lisis comparativo y trade-offs

**Accuracy vs Dimensionalidad**:  
  - **Label** logra el mejor accuracy con solo **14 features**.  
  - **Target** comprime a **6 features**, sacrificando ~6 p.p. de accuracy vs Label.
**Accuracy vs Tiempo**:  
  - Los tiempos son similares (~0.43‚Äì0.45s). Si el costo crece (dataset grande), **Target/Binary** escalan mejor en columnas.
**Mantenibilidad/Producci√≥n**:  
  - **Pipeline con `ColumnTransformer`**: separa ramas por tipo, evita fugas, serializa transformadores y es **auditable**.

![AUC/Accuracy vs smoothing en Target](../assets/ent8_prac9_D1_AUC_ACCURACY_etc.png){ width="800" }

![columnas creadas por Binary vs One-Hot en la misma variable](../assets/ent8_prac9_C1_barras_verticales_importancia_promedio_por_feature.png){ width="800" }

---

### 3) Investigaci√≥n Libre (t√©cnicas avanzadas)

- **Frequency Encoding**: mapea categor√≠a ‚Üí frecuencia (sin target).  
  - Pros: simple, sin leakage; Cons: menos expresivo que Target.
- **Ordinal Encoding**: para variables con **orden natural** (p.ej., educaci√≥n).  
  - Beneficia modelos lineales/ordinales; evita ‚Äúorden inventado‚Äù.
- **Leave-One-Out Target Encoding**: promedio por categor√≠a excluyendo el registro actual.  
  - Reduce overfitting vs Target naive; m√°s costo computacional.
- **Binary Encoding** (`category_encoders.BinaryEncoder`): columnas ‚âà `ceil(log2(n_categor√≠as))`.  
  - √ötil en **alta cardinalidad** sin sobrecargar dimensionalidad.
- **Smoothing en Target**: mezcla media por categor√≠a con media global (1, 10, 100, 1000).  
  - Smoothing **alto** estabiliza categor√≠as raras; **bajo** es m√°s flexible pero ruidoso.

---

## Reflexi√≥n

**1) ¬øQu√© m√©todo funcion√≥ mejor y por qu√©?**  
- **Label Encoding** (con RF) obtuvo los mejores **Accuracy/AUC/F1**. Los √°rboles no sufren por el ‚Äúorden artificial‚Äù de las etiquetas y aprovechan bien splits por c√≥digo.

**2) Trade-offs clave**  
- **One-Hot**: m√°s interpretable pero **dimensi√≥n‚Üë** sin grandes mejoras.  
- **Target**: **compacto** y expresivo, pero requiere **cuidados anti-leakage**.  
- **Pipeline**: rendimiento alto, **modularidad** y reproducibilidad ‚Üí elecci√≥n preferida en **producci√≥n**.

**3) Data Leakage**  
- Evitado con: *fit en train*, **CV**, y/o pipelines (transform ‚Üí model).  
- Target/LOO **siempre** con guardrails (no usar informaci√≥n de test/valid).

**4) Alta cardinalidad**  
- One-Hot **falla** (explosi√≥n de columnas, sparsidad).  
- Preferir **Target**, **Binary** o **Freq** (seg√∫n modelo y costo).

**5) Pipeline Branching**  
- `ColumnTransformer` permite **ramificar** por tipo de variable y controlar cada transformaci√≥n, con **coherencia** entre train/test y **menos riesgos**.

---

## Recomendaciones t√©cnicas (para un proyecto real)
- **Producci√≥n**: `Pipeline(preprocessor=ColumnTransformer([...]), classifier=RF)` + control de leakage.  
- **Encoding mix**: One-Hot (baja card), Target/Binary (alta), Ordinal (si existe orden natural).  
- **Monitoreo**: observar **m√©tricas por segmento** (fairness/calibraci√≥n) y re-entrenos.  
- **Explicabilidad**: combinar **importancias** con **SHAP** para verificar estabilidad e interacciones.

---

## Preguntas conceptuales clave (respuestas breves)
- **Leakage en Target**: usar target del fold/test en el encoding. **Prevenci√≥n**: fit solo en train, CV, pipeline.  
- **One-Hot vs alta cardinalidad**: explota columnas y sparsidad ‚Üí costo y overfitting.  
- **Smoothing en Target**: regulariza categor√≠as raras mezclando con media global.  
- **Cu√°ndo Label/Target/One-Hot**:  
  - **Label**: √°rboles / bajo costo.  
  - **One-Hot**: pocas categor√≠as, interpretabilidad.  
  - **Target**: alta cardinalidad (con anti-leakage).  
- **Ventajas `ColumnTransformer`**: ramificado, reproducible, sin fugas, auditable.  
- **Categor√≠as no vistas (test)**: One-Hot `handle_unknown='ignore'`, Label `-1`, Target media global.  
- **Trade-off accuracy vs dimensionalidad**: m√°s columnas ‚â† mejor; equilibrar se√±al vs costo y riesgo de sobreajuste.

---

## Conclusiones Finales

- El m√©todo de encoding influye directamente en la capacidad predictiva del modelo.  
- Los modelos de √°rboles se benefician de Label y Target Encoding.  
- El uso de pipelines con ColumnTransformer evita fugas y mejora la reproducibilidad.  
- Las features num√©ricas siguen siendo las m√°s determinantes.  
- La comprensi√≥n de *fairness* y *explicabilidad* es clave para modelos √©ticos y robustos.

---

## Referencias
- UCI ML Repository ‚Äî Adult Income  
- [Documentaci√≥n de Scikit-learn](https://scikit-learn.org/stable/) 
- [Documentaci√≥n de `ColumnTransformer` (sklearn.compose.ColumnTransformer)](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)
- [Documentaci√≥n de Category Encoders](https://contrib.scikit-learn.org/category_encoders/)
- [Documentaci√≥n de Fairlearn](https://fairlearn.org/)

---
