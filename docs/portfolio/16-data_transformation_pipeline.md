---
title: "üìä‚öôÔ∏è Preparaci√≥n y Enriquecimiento de Datos en Cloud Dataprep"
date: 2025-12-05
---

# üìä‚öôÔ∏è Preparaci√≥n y Enriquecimiento de Datos en Cloud Dataprep

## Contexto

En esta actividad se complet√≥ el lab intermedio **"Creating a Data Transformation Pipeline with Cloud Dataprep" (GSP430)** de Google Cloud Skills Boost. Este lab brind√≥ experiencia pr√°ctica con **Cloud Dataprep (Alteryx Designer Cloud)**, una herramienta visual para explorar, limpiar y transformar datos antes de an√°lisis o carga en data warehouses. Se construy√≥ un pipeline completo que toma datos desde BigQuery, los procesa en Dataprep, y publica los resultados nuevamente en BigQuery.


**Fuente**: [Creating a Data Transformation Pipeline with Cloud Dataprep (GSP430)](https://www.skills.google/focuses/4415)  
**Nivel:** Intermedio  
**Duraci√≥n:** 75 minutos

---

## Objetivos

- Entender la interfaz y funcionalidades de Cloud Dataprep  
- Conectar datasets de BigQuery como origen y destino  
- Explorar calidad de datos con herramientas visuales  
- Construir un pipeline de limpieza y enriquecimiento  
- Crear columnas calculadas y transformaciones complejas  
- Ejecutar un job de Dataprep usando Dataflow  
- Exportar resultados a BigQuery  
- Comprender el flujo end-to-end BigQuery ‚Üí Dataprep ‚Üí BigQuery

---

## Actividades (con tiempos estimados)

| Actividad                          | Tiempo | Resultado esperado |
|-----------------------------------|:------:|-------------------|
| Configuraci√≥n inicial             | 10m    | Dataprep habilitado |
| Creaci√≥n de dataset en BigQuery   | 10m    | Dataset `ecommerce` creado |
| Conexi√≥n BigQuery ‚Üí Dataprep      | 10m    | Flow configurado |
| Exploraci√≥n de datos              | 15m    | Quality profiling realizado |
| Limpieza de datos                 | 15m    | Recipe con transformaciones |
| Enriquecimiento                   | 15m    | Columnas calculadas |
| Ejecuci√≥n del pipeline            | 10m    | Tabla final en BigQuery |

---

## Desarrollo

### 1. Configuraci√≥n Inicial de Cloud Dataprep

#### Habilitaci√≥n del servicio

Se cre√≥ la identidad necesaria para Dataprep:

```bash
gcloud beta services identity create --service=dataprep.googleapis.com
````

Luego se accedi√≥ al servicio desde:

**Navigation Menu ‚Üí Analytics ‚Üí Alteryx Designer Cloud**

Incluyendo aceptaci√≥n de t√©rminos, permisos, autenticaci√≥n con Qwiklabs y configuraci√≥n del bucket de almacenamiento.

*Nota:* Cloud Dataprep requiere Google Chrome.

---

## 2. Creaci√≥n de Dataset en BigQuery

Se cre√≥ el dataset `ecommerce` y luego la tabla base con:

```sql
CREATE OR REPLACE TABLE ecommerce.all_sessions_raw_dataprep AS
SELECT *
FROM `data-to-insights.ecommerce.all_sessions_raw`
WHERE date = '20170801'; 
```

Esto gener√≥ ~56.000 filas del Google Merchandise Store.

---

### 3. Conexi√≥n de BigQuery a Cloud Dataprep

Pasos:

1. Crear Flow ‚Üí `Ecommerce Analytics Pipeline`
2. A√±adir dataset desde BigQuery
3. Seleccionar tabla `all_sessions_raw_dataprep`

Dataprep analiza estructura, tipos y calidad.

---

### 4. Exploraci√≥n Visual de Datos

Dataprep permite:

#### Panel de esquema

* Columnas y tipos
* Detecci√≥n autom√°tica de inconsistencias

#### Vista tabular

* Histogramas por columna
* Outliers y valores faltantes

#### Panel de sugerencias

* Transformaciones recomendadas

#### Hallazgos clave

* Varias columnas nulas
* Revenue multiplicado por 1e6
* Tipos de hit diversos
* Datos de sesi√≥n complejos

---

### 5. Limpieza de Datos

#### 5.1 Filtrar por `type = "PAGE"`

Se seleccionaron solo visualizaciones de p√°ginas.

#### 5.2 Quitar columnas irrelevantes

Columnas nulas, redundantes o no √∫tiles para an√°lisis.

---

### 6. Enriquecimiento de Datos

#### 6.1 Crear identificador √∫nico

Se cre√≥ `unique_session_id` concatenando:

```
fullVisitorId + "-" + visitId
```

#### 6.2 Etiquetas descriptivas de acciones e-commerce

`eCommerceAction_type` (0‚Äì8) ‚Üí `eCommerceAction_label`
Creado mediante **Case Statement**.

#### 6.3 Normalizar revenue

```
DIVIDE(totalTransactionRevenue, 1000000)
```

Nueva columna: `totalTransactionRevenue1` ‚Üí tipo Decimal.

---

### 7. Ejecuci√≥n del Pipeline en Dataflow

Configuraci√≥n:

* Ambiente: **Dataflow + BigQuery**
* Crear nueva tabla
* Nombre destino: `revenue_reporting`
* Opci√≥n: *Drop table on every run*

Proceso:

1. Validaci√≥n
2. Compilaci√≥n a Apache Beam
3. Ejecuci√≥n distribuida
4. Escritura en BigQuery

Verificaci√≥n final: tabla `revenue_reporting` disponible y correcta.

---

## Conceptos Clave Aprendidos

### Cloud Dataprep

* Preparaci√≥n visual de datos
* Detecci√≥n autom√°tica de problemas
* Transformaciones sin c√≥digo
* Integraci√≥n nativa con BigQuery

### Recipes y Flows

* Flow: pipeline completo
* Recipe: pasos de transformaci√≥n
* Dataset: origen conectado

### Tipos de transformaciones

* Filtrado
* Eliminaci√≥n de columnas
* Enriquecimiento
* Case statements
* F√≥rmulas personalizadas
* Joins, pivots y agregaciones

### BigQuery ‚Üî Dataprep

* Lectura/escritura directa
* Ideal para anal√≠tica y warehousing

### Dataflow

* Escalabilidad
* Paralelizaci√≥n
* Monitoreo y logging de ejecuci√≥n

---

## Aplicaciones Pr√°cticas y Usos Futuros

### Machine Learning

* Preparar features
* Crear datasets limpios
* Manejar valores faltantes

### ETL para Data Warehousing

* Pipelines visuales
* Reglas de negocio documentadas
* Integraci√≥n con BigQuery

### Google Analytics

* Limpieza
* Mapeos descriptivos
* Reporting avanzado

### Data Quality

* Perfilado de columnas
* Validaci√≥n de valores
* Auditor√≠as r√°pidas

### Colaboraci√≥n

* No-code para analistas
* Documentaci√≥n visual
* Revisi√≥n colaborativa de transformaciones

---

## Desaf√≠os y Observaciones

#### Interfaz abrumadora al inicio

Soluci√≥n: seguir el flujo b√°sico Flow ‚Üí Recipe ‚Üí Transformaciones.

#### Necesidad de usar Chrome

Limitaci√≥n t√©cnica del servicio.

#### Transformaciones complejas

Case statements requieren planificaci√≥n previa.

#### Jobs lentos

Utilizar subsets para desarrollo.

#### Debugging

Revisar paso a paso con vista previa.

---

## Reflexiones Finales

### Fortalezas

* Pipeline end-to-end
* Datos reales
* Exploraci√≥n guiada
* Integraci√≥n fluida con BigQuery

### √Åreas de mejora

* Tiempo limitado
* Dataset peque√±o
* Pocos ejemplos avanzados

### Comparaci√≥n

* SQL: r√°pido para tareas simples, menos visual
* Python ETL: m√°s flexible, menos accesible
* Dataflow manual: m√°s control, m√°s complejo

### Valor para Ingenier√≠a de Datos

* Herramienta esencial para exploraci√≥n
* Acelera prototipos
* Ideal para equipos mixtos
* Excelente para preparaci√≥n previa a ML

---

## Decisiones y Pr√≥ximos Pasos

### Decisiones tomadas

* Filtrar `PAGE`
* Crear ID √∫nico
* Mapeos descriptivos
* Normalizar revenue
* Sobrescribir tabla en cada corrida

### Pr√≥ximos pasos

* Usar datasets grandes
* Probar joins y pivots
* Integrar Cloud Storage
* Automatizar pipelines
* Completar labs avanzados

---

## Conclusiones

Este lab demuestra el ciclo completo de preparaci√≥n de datos usando Google Cloud: BigQuery ‚Üí Dataprep ‚Üí Dataflow ‚Üí BigQuery. La preparaci√≥n visual acelera el an√°lisis, mejora la calidad de datos y facilita la colaboraci√≥n.

**Takeaways clave:**

* La preparaci√≥n visual puede ser tan poderosa como el c√≥digo
* Explorar antes de transformar es esencial
* GCP ofrece integraci√≥n nativa y fluida
* Las herramientas visuales aumentan la colaboraci√≥n
* Dataprep es ideal para prototipado y limpieza intensiva de datos

---

## Referencias

* Google Cloud Skills Boost
* Lab GSP430: Creating a Data Transformation Pipeline with Cloud Dataprep
* Cloud Dataprep Docs
* Alteryx Designer Cloud
* BigQuery Docs
* Dataflow Docs
