---
title: "05 Feature scaling y anti leakage pipeline (Ames Housing)"
date: 2025-09-21
---

# Escalado, Outliers y Pipelines (Ames Housing)

## Contexto
Pr√°ctica de Ingenier√≠a de Datos enfocada en **preprocesamiento num√©rico**: detecci√≥n de outliers, efecto del **escalado de features**, elecci√≥n de transformadores y **prevenci√≥n de data leakage** al construir pipelines reproducibles. Se trabaj√≥ con el dataset **Ames Housing** (2930 filas, 82 columnas). Se introdujeron faltantes sint√©ticos para ejercitar imputaci√≥n y an√°lisis de sesgo.

## Objetivos
- Identificar cu√°les features del dataset Ames **necesitan escalado** y por qu√©.  
- Experimentar con **MinMaxScaler, StandardScaler y RobustScaler** en datos reales.  
- Descubrir el **impacto del escalado** en diferentes algoritmos mediante experimentaci√≥n.  
- Comparar **pipelines con y sin data leakage** para ver las diferencias.  
- Decidir **la mejor estrategia** bas√°ndose en evidencia emp√≠rica.

## Actividades (con tiempos estimados)
- Preparaci√≥n de entorno y dataset ‚Äî **25 min**  
- Exploraci√≥n inicial (escalas, outliers, ratios) ‚Äî **25 min**  
- Experimentos con escalers cl√°sicos (Standard/MinMax/Robust) ‚Äî **30 min**  
- Trabajo independiente con transformador avanzado (**PowerTransformer ‚Äì Yeo-Johnson**) ‚Äî **50 min**  
- Demostraci√≥n anti-leakage (m√©todo incorrecto, correcto y **Pipeline**) ‚Äî **35 min**  
- Validaci√≥n con **cross-validation** y baseline ‚Äî **30 min**  
- Redacci√≥n de evidencias y conclusiones ‚Äî **30 min**  
- Subida y formateo para el portfolio ‚Äî **50 min**

---

## Desarrollo
1. **Exploraci√≥n y escalas.** Se calcularon rangos y ratios *max/min* por columna y se graficaron **boxplots en log1p** e **histogramas**. Emergieron como variables problem√°ticas: `Lot Area`, `Misc Val`, `Total Bsmt SF` y `SalePrice` (colas largas y fuerte asimetr√≠a).  
2. **Outliers.** Se aplicaron **IQR** y **Z-Score** (umbral=3) a los datos originales y luego a los datos escalados con tres scalers.  
3. **Transformador avanzado.** Se evalu√≥ **PowerTransformer (Yeo-Johnson)** para corregir asimetr√≠a (no lineal, aprende Œª por m√°xima verosimilitud).  
4. **Leakage.** Se compararon tres flujos:  
   - ‚ùå Escalar todo y despu√©s *train/test split* (con leakage).  
   - ‚úÖ Split primero y escalar **solo con train** (sin leakage).  
   - ‚úÖ `sklearn.Pipeline` (anti-leakage autom√°tico).  
5. **Validaci√≥n.** Se hizo un pipeline (**PowerTransformer + KNN**) y se evalu√≥ con **CV=5** y baseline (`DummyRegressor`).

---

## Evidencias

- [Notebook completo en nbviewer](https://nbviewer.org/github/naguer019/IA-portfolio/blob/main/docs/recursos_files/cuatro_cinco_prac_6.ipynb)

### 1) Exploraci√≥n de escalas (ratios y outliers visuales)

**C√≥mo se hizo**  
- C√°lculo de **rango** y **ratio `max/min`** por columna num√©rica.  
- **Boxplots con `np.log1p`** para comparar escalas y ver colas largas.  
- **Histogramas** para confirmar sesgo y valores extremos.

**Qu√© muestran**  
- Top escalas "notorias" o "fuertes": `Lot Area`, `Misc Val`, `Total Bsmt SF`, `SalePrice`.  
- **Ratios altos** y colas largas ‚Üí riesgo para algoritmos basados en distancia (KNN/SVM).

![Boxplots log1p](../assets/boxplots_log1p_ent5_prac6.png){ width="720" }  
![Histogramas con variables seleccionadas](../assets/hists_variables_ent5_prac6.png){ width="720" }

---

### 2) Outliers antes/despu√©s de escalar

**C√≥mo se hizo**  
Se midi√≥ el conteo de outliers con **IQR** y **Z-Score** en:
- Datos **originales**.  
- Datos escalados con **StandardScaler**, **MinMaxScaler** y **RobustScaler**.

**Resultados (ej. en `Lot Area`)**  
- **IQR (original):** 127 outliers  
- **Z-Score (original):** 29 outliers  
- **Post-Standard:** IQR 127 / Z 29  
- **Post-MinMax:** IQR 127 / Z 29  
- **Post-Robust:** IQR 127 / Z 29  

**Interpretaci√≥n**  
- El escalado **no cambia qu√© puntos caen fuera de los umbrales** IQR/Z para esta columna; **s√≠** modifica la **representaci√≥n** (menos ‚Äúdominancia‚Äù visual).  
- **RobustScaler** reduce la influencia de extremos (mediana/IQR), pero no corrige **asimetr√≠a**.

![Boxplots individuales previo a escalado (post-escalado se mantuvo igual el conteo de outliers)](../assets/boxplots_individuales_ent5_prac6.png){ width="720" }



---

### 3) Transformador avanzado ‚Äî PowerTransformer (Yeo-Johnson) (hecho en investigaci√≥n independiente)

**C√≥mo se hizo**  
- Apliqu√© `PowerTransformer(method="yeo-johnson", standardize=True)` a `Lot Area`, `Misc Val`, `Total Bsmt SF`, `SalePrice`.  
- Compar√© **skewness/kurtosis** y rangos **antes vs despu√©s**.

**Qu√© muestran**  
- **Reducci√≥n fuerte de asimetr√≠a** y compresi√≥n de colas en las cuatro columnas.  
- A diferencia de los scalers lineales, Yeo-Johnson **cambia la forma de la distribuci√≥n**.

Ejemplo de como afecta el PowerTransformer a la distribuci√≥n (cercano a una normalizaci√≥n)
![Cambio en la distribuci√≥n de una variable con PowerTransformer)](../assets/powertransformer_antesdespues_ent5_prac6.png){ width="720" }


**Nota te√≥rica**  
Yeo-Johnson aplica una transformaci√≥n de potencia **no lineal** que admite \(x \le 0\) y estima un \(\lambda\) por m√°xima verosimilitud. (Inclu√≠ en el notebook la ecuaci√≥n completa en LaTeX en lugar de aqu√≠ para no sobrecargar).

**¬øC√≥mo funciona?**

Funcionamiento (para Yeo-Johnson): 

1. Se estima un par√°metro $\lambda$ autom√°ticamente con m√°xima verosimilitud para cada feature. Ese par√°metro es el que "mejor normaliza" la distribuci√≥n.

2. Los valores positivos y negativos se tratan diferente:
    - Para x $\ge$ 0, es bastante parecido a Box-Cox (m√©todo solo para mayores o iguales a 0)
    - Para x $<$ 0, se usa otra f√≥rmula para asegurar la continuidad.

3. El resultado es que los datos transformados tienen asimetr√≠a reducida (skew apr√≥ximadamente 0) y una varianza m√°s estable.


**Razones para elegir PowerTransformer**

- Diferenci√°ndose de StandardScaler, que solo centra y escala, PowerTransformer corrige la asimetr√≠a de las distribuciones. Siendo √∫til en el dataset actual de Ames Housing al tener variables como SalePrice o Lot Area que presentan colas largas y outliers que distorsionan modelos sensibles a la normalidad.

- Como ventaja principal, permite que los datos se parezcan m√°s a una distribuci√≥n normal, lo cual mejora el desempe√±o de los modelos lineales y algoritmos basados en supuestos gaussianos (como regresi√≥n lineal, PCA, etc).

- M√©todos disponibles:
    * Box-Cox (solo valores positivos)
    * Yeo-Johnson (acepta negativos y ceros)

- Como limitaciones, por ejemplo, no siempre mejora los resultados si la variable ya est√° cerca de ser normal. Pudiendo tambi√©n dificultar la interpretabilidad, ya que los valores transformados dejan de representar magnitudes reales como "precio en d√≥lares" o "metros cuadrados".

- Dando un ejemplo con el dataset que estuvimos trabajando, en Ames Housing, aplicar PowerTransformer sobre SalePrice o LotArea ayuda a reducir el sesgo positivo y facilita la comparaci√≥n entre viviendas de distinto rango de precios o tama√±os de terreno.

---

### 4) Demostraci√≥n de **data leakage**

**Configuraci√≥n**  
Modelo **KNN (k=5)**, features: `Lot Area`, `Misc Val`, `Total Bsmt SF` (sin IDs). Comparaci√≥n de tres flujos.

**Resultados**

| M√©todo                     | R¬≤     | MAE     |
|---------------------------|--------|---------|
| **Con leakage**           | 0.1846 | 36,914  |
| **Sin leakage**           | 0.1957 | 36,443  |
| **Pipeline (correcto)**   | 0.1957 | 36,443  |
| Baseline (Dummy median)   | ‚àí0.0443| 39,416  |

**Qu√© muestra**  
- El leakage alter√≥ las m√©tricas (ŒîR¬≤ ‚âà **+0.011**, ŒîMAE ‚âà **‚àí472**). En este dataset el impacto fue **chico pero real**; en otros puede inflarlas mucho m√°s.  
- **Pipeline** garantiza el orden correcto (**fit en train** ‚Üí **transform en train/test**) y se integra con **cross-validation**.

---

### 5) Validaci√≥n final con *cross-validation*

**Pipeline final**: `PowerTransformer (Yeo-Johnson) + KNN`  
**CV=5 (R¬≤ y MAE):**

- **R¬≤ folds:** `[0.0340, 0.1525, 0.1490, 0.0223, 0.2254]` ‚Üí **media=0.1166 ¬± 0.0773**  
- **MAE folds:** `[38486.15, 33607.41, 30842.81, 34818.02, 32191.66]` ‚Üí **media=33,989 ¬± 2,615**

**Baseline (Dummy median, CV=5):**  
- **R¬≤:** media ‚âà **‚àí0.0248**  
- **MAE:** media ‚âà **35,194**

**Conclusi√≥n**  
El pipeline supera claramente al baseline ‚Üí **aporta valor real**. El R¬≤ a√∫n es modesto: hay margen para mejorar con m√°s features y modelos.

---

## Conclusiones
- **PowerTransformer (Yeo-Johnson)** fue el mejor para variables con **sesgo y colas largas** (Ames las tiene).  
- El **orden importa**: analizar/mitigar outliers **antes** de escalar.  
- **Scalers lineales** (Standard/MinMax/Robust) no cambian la forma; Yeo-Johnson s√≠.  
- **Pipeline + CV** evita leakage y da evaluaci√≥n honesta.  
- Pipeline final (**Yeo-Johnson + KNN**) > baseline en R¬≤ y MAE.

---

## Recomendaci√≥n final (pipeline)
1. **Detecci√≥n/tratamiento de outliers** en crudo (IQR/Z + criterio de dominio).  
2. **Train/Test split** al inicio.  
3. **PowerTransformer (Yeo-Johnson)** para features sesgadas; StandardScaler para el resto.  
4. **Modelo sensible a escala** (p.ej., KNN/SVM) dentro de **`Pipeline`**.  
5. **Cross-validation** y baseline para contrastar.


## üèÜ MI CHECKLIST PERSONAL PARA PROYECTOS DE DATOS:

- 1. ¬øLas features est√°n en escalas muy diferentes? -> Revisar min, max, ratio
- 2. ¬øMi proceso necesita escalado?  -> Si, si uso KNN, regresi√≥n lineal.
- 3. ¬øHay outliers evidentes? ‚Üí Analizar con IQR/Z-score; considerar RobustScaler si no los elimino.
- 4. ¬øDatos muy sesgados? ‚Üí Aplicar PowerTransformer o log transform.
- 5. ¬øEstoy usando Pipeline? ‚Üí Siempre (anti-leakage autom√°tico).
- 6. ¬øSplit ANTES de transformar? ‚Üí Obligatorio para evitar leakage.
- 7. ¬øCross-validation honesta? ‚Üí Pipeline + CrossValidation para evaluaci√≥n estable.
- 8. ¬øResultados realistas vs optimistas? ‚Üí Verificar leakage y baseline como referencia.
- 9. ¬øDocument√© mi elecci√≥n de transformadores? -> S√≠, con justificaci√≥n basada en evidencia.
- 10. ¬øMi pipeline es reproducible? -> S√≠, con random_state y pasos claros.
 
---

## Referencias
- Dataset: **Ames Housing** (Kaggle).  
- `scikit-learn` ‚Äî `StandardScaler`, `MinMaxScaler`, `RobustScaler`, `PowerTransformer`, `Pipeline`, `cross_val_score`.  
- [Link a la gu√≠a de la pr√°ctica](https://juanfkurucz.com/ucu-id/ut2/06-feature-scaling-pipeline/)
