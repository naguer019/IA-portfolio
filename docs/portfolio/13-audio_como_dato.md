---
title: "üîä Escuchando la ciudad: preprocesamiento de audio y MFCC en UrbanSound8K"
date: 2025-11-19
---

# üîä Escuchando la ciudad: preprocesamiento de audio y MFCC en UrbanSound8K

## Contexto  

En esta pr√°ctica trabaj√© con el dataset **UrbanSound8K** (sonidos urbanos etiquetados en 10 clases), descargado desde Kaggle mediante `kagglehub`.  
El objetivo general fue dise√±ar un **pipeline de preprocesamiento de audio** que deje todos los clips en un formato est√°ndar y extraer **representaciones espectrales y MFCCs** para futuros modelos de clasificaci√≥n de audio.

A diferencia de pr√°cticas anteriores centradas en im√°genes, ac√° el foco estuvo en:
- pasar de la **se√±al cruda en el tiempo** a representaciones **tiempo‚Äìfrecuencia** y
- resumir el audio en **features tabulares** listos para Machine Learning.

---

## Objetivos

- Cargar y explorar un clip del dataset **UrbanSound8K** (waveform y estad√≠sticas b√°sicas).
- Definir un **est√°ndar de entrada**: sample rate, duraci√≥n fija, normalizaci√≥n y mono.
- Comparar **espectrogramas** antes y despu√©s del preprocesamiento.
- Analizar el efecto de **ruido blanco** y de filtrado **high-pass** sobre el espectro.
- Extraer **MFCCs y m√©tricas de energ√≠a** y guardarlas en un **CSV**.
- Explorar m√©tricas espectrales din√°micas, la distribuci√≥n de folds y ejemplos de **data augmentation** (pitch shift y time stretch).

---

## Actividades (con tiempos estimados)

- Descarga del dataset y exploraci√≥n b√°sica de archivos ‚Äî 15 min  
- Visualizaci√≥n inicial (waveform + espectrogramas STFT / Mel) ‚Äî 25 min  
- Dise√±o del pipeline de preprocesamiento (trim, resampleo, padding, normalizaci√≥n) ‚Äî 30 min  
- Experimentos con ruido blanco y filtro high-pass ‚Äî 30 min  
- Extracci√≥n de MFCCs y construcci√≥n del CSV de features ‚Äî 30 min  
- Exploraciones avanzadas (m√©tricas espectrales, folds, augmentations) ‚Äî 30 min  
- Documentaci√≥n de resultados y reflexiones ‚Äî 30 min  

---

## Desarrollo

### 1. Dataset y carga de audio

El dataset se descarg√≥ con `kagglehub` desde:

- **Dataset:** `chrisfilo/urbansound8k`  
- **Ruta local:** `~/.cache/kagglehub/datasets/chrisfilo/urbansound8k/versions/1`  
- **Cantidad de audios encontrados:** **8732 clips** (`*.wav`).

Para la exploraci√≥n inicial tom√© el primer archivo:

- `101415-3-0-2.wav`  
- Sample rate original: **48000 Hz**  
- Duraci√≥n: **4.0 s**  
- Canales: **1 (mono)**  
- Tipo de dato: **float32**  
- Rango de amplitud: **[‚àí0.8535, 0.8065]**  
- Media ~0.0 y desviaci√≥n est√°ndar ‚âà 0.1133.

Trabajar en **mono** es suficiente para clasificaci√≥n de sonidos urbanos: reduce la complejidad y el tama√±o de los datos a la mitad y, en este contexto, la informaci√≥n est√©reo no es cr√≠tica.

En cuanto a la amplitud, los valores est√°n entre ~‚àí0.85 y 0.81, es decir, **no est√° normalizada** al rango completo [‚àí1, 1], y tampoco hay evidencia de clipping (no hay picos cercanos a ¬±1.0 saturados).

![Waveform mono](../assets/14-waveform-mono.png){ width="800" }  
*Fig. 1 ‚Äî Forma de onda mono del clip 101415-3-0-2.wav: se observan tres eventos impulsivos y un bloque de actividad m√°s larga al final.*

Para entender mejor la estructura temporal y frecuencial del clip, se gener√≥ una visualizaci√≥n combinada:

- **Waveform** en el tiempo.
- **Espectrograma STFT** (frecuencia lineal en Hz).
- **Espectrograma de Mel** (frecuencias en escala perceptual).

![Waveform y espectrogramas](../assets/14-waveform-stft-mel.png){ width="900" }  
*Fig. 2 ‚Äî Arriba, waveform; al medio, espectrograma STFT; abajo, espectrograma de Mel. Los primeros segundos son golpes aislados y, entre 2.5‚Äì4 s, un sonido m√°s continuo y modulando en altura.*

> Nota conceptual: valores cercanos a ¬±1.0 de forma constante indicar√≠an **clipping**, que produce distorsi√≥n no lineal y p√©rdida irreversible de informaci√≥n. En este clip no se observa ese problema.

---

### 2. Estandarizaci√≥n del audio

Para poder entrenar modelos en lote, se defini√≥ un **formato est√°ndar de entrada**:

- `TARGET_SR = 16000 Hz`  
- `TARGET_DURATION = 3.0 s`  
- Se√±al en **mono**  
- Amplitud normalizada con pico ‚âà **0.99**  
- Recorte de silencios con `top_db = 30 dB`.

El pipeline de preprocesamiento aplicado a cada clip fue:

1. **Cargar audio** en su sample rate original.  
2. Si hay m√∫ltiples canales, promediar a **mono**.  
3. **Recortar silencios** con `librosa.effects.trim(y, top_db=30)`.  
4. **Resamplear** a 16 kHz si es necesario.  
5. **Ajustar duraci√≥n** a 3 segundos:
   - Si sobra audio: se recorta.
   - Si falta: se hace padding con ceros al final.  
6. **Normalizar amplitud** para que el valor absoluto m√°ximo sea ‚âà 0.99.

Tras este proceso, el clip qued√≥:

- Forma: 48000 muestras  
- Sample rate: 16000 Hz  
- Duraci√≥n: **3.0 s**  
- Rango de amplitud: **[‚àí0.99, 0.93]**.

![Waveform original vs estandarizada](../assets/14-waveform-original-vs-std.png){ width="900" }  
*Fig. 3 ‚Äî Arriba, waveform original de 4 s; abajo, waveform estandarizada a 3 s, 16 kHz y amplitud normalizada.*

**Justificaci√≥n de par√°metros clave:**

- **16 kHz** es un est√°ndar com√∫n en voz y audio para ML: cubre bien el rango de inter√©s (frecuencias √∫tiles hasta 8 kHz, por Nyquist) y reduce el tama√±o respecto a 44.1/48 kHz (~2.7√ó menos muestras).
- El recorte de silencios con `top_db = 30` elimina principalmente **silencios suaves y ruido de fondo**, sin afectar las partes de alta energ√≠a del evento.
- La normalizaci√≥n a pico 0.99 **aprovecha mejor el rango din√°mico** y hace comparables los clips, sin introducir clipping.
- Si la duraci√≥n est√°ndar fuera **5.0 s** en lugar de 3.0 s, cada clip pasar√≠a de 48000 a 80000 muestras (16 kHz), aumentando significativamente el tama√±o en disco y el costo de procesamiento, aunque permitiendo capturar eventos m√°s largos.
- Recortar siempre desde el **centro del clip** (en lugar de al inicio) podr√≠a ser √∫til si el evento principal suele estar centrado en el audio, pero requiere m√°s l√≥gica; para UrbanSound8K, el recorte por duraci√≥n despu√©s del trim resulta razonable.

---

### 3. Espectrogramas, ruido y filtrado

Para analizar el contenido frecuencial se generaron espectrogramas STFT con:

- `n_fft = 2048`  
- `hop_length = 512`  

lo que implica:

- Ventanas de **128 ms** (`2048 / 16000`)  
- Avance entre ventanas de **32 ms** (`512 / 16000`).

Comparando el espectrograma original y el estandarizado se observa que:

- La estructura general de los eventos se mantiene.  
- El estandarizado concentra la energ√≠a en los 3 s elegidos y se limita al rango de 16 kHz (en lugar de 24 kHz de la versi√≥n original a 48 kHz).

![Espectrograma original](../assets/14-spec-original.png){ width="900" }  
*Fig. 4 ‚Äî Espectrograma original (4 s, 48 kHz). Se aprecia energ√≠a en frecuencias bajas y medias, con actividad intensa en el √∫ltimo segundo.*

![Espectrograma estandarizado](../assets/14-spec-standardized.png){ width="900" }  
*Fig. 5 ‚Äî Espectrograma del audio estandarizado (3 s, 16 kHz). El contenido principal se conserva dentro del nuevo rango de frecuencias.*

#### Ruido blanco (SNR ‚âà 10 dB)

Se a√±adi√≥ **ruido blanco** con una relaci√≥n se√±al-ruido objetivo de **10 dB**, calculando la potencia de la se√±al y ajustando la potencia del ruido en consecuencia.  

En el espectrograma, el ruido blanco se observa como:

- un ‚Äútapizado‚Äù uniforme de energ√≠a en casi todas las frecuencias,  
- sin patrones estructurados,  
- elevando el suelo de ruido en todo el espectro.

![Espectrograma con ruido blanco](../assets/14-spec-noisy.png){ width="900" }  
*Fig. 6 ‚Äî Espectrograma del audio estandarizado con ruido blanco (SNR ‚âà 10 dB): fondo m√°s ‚Äúgranulado‚Äù que oculta parte de los detalles finos.*

#### Filtro high-pass (80 Hz)

Luego se aplic√≥ un filtro **high-pass Butterworth de 4¬∫ orden** con corte en **80 Hz**, pensado para eliminar ruidos muy graves (vibraciones, rumbles, etc.).

![Espectrograma tras high-pass](../assets/14-spec-highpass.png){ width="900" }  
*Fig. 7 ‚Äî Espectrograma despu√©s del filtro high-pass a 80 Hz: se aten√∫an las componentes de muy baja frecuencia, manteniendo pr√°cticamente intacta la se√±al √∫til.*

Comentarios:

- La mayor√≠a de sonidos urbanos y voces tienen energ√≠a relevante por encima de ~100 Hz, por lo que un corte en 80 Hz **elimina principalmente ruido de muy baja frecuencia**.
- Para eliminar **hum de red (50/60 Hz)** ser√≠a m√°s adecuado un **filtro notch** muy selectivo en 50 o 60 Hz (y, si es necesario, en sus arm√≥nicos) en lugar de un high-pass agresivo que podr√≠a eliminar componentes graves √∫tiles.
- Cambiar a `n_fft = 1024` y `hop_length = 256` mejorar√≠a la **resoluci√≥n temporal** (ventanas de 64 ms), a costa de peor resoluci√≥n en frecuencia y mayor cantidad de frames.

---

### 4. Extracci√≥n de MFCC y features tabulares

Para pasar de representaciones tiempo‚Äìfrecuencia a una vista **tabular** apta para modelos cl√°sicos, se extrajeron **MFCCs** y otras m√©tricas:

- **13 coeficientes MFCC** por frame (`n_mfcc = 13`).  
- Para cada coeficiente `i`, se guardaron:
  - `mfcc_i_mean` y `mfcc_i_std`.  
- Adem√°s:
  - `rms_mean` (energ√≠a media RMS).  
  - `zcr_mean` (tasa de cruces por cero media).

En total, cada clip queda resumido en:

- `13 √ó 2 = 26` features de MFCC  
- `+ 2` features adicionales (RMS, ZCR)  
- `+ 3` metadatos (`filename`, `sr`, `duration_sec`)  

para un total de **31 columnas** en el DataFrame resultante.

Se procesaron los primeros **100 audios** del dataset con el pipeline est√°ndar y se guardaron las features en:

- `outputs/features/audio_mfcc_features.csv`  
- Shape del DataFrame: **(100, 31)**.

**Justificaci√≥n de n_mfcc = 13:**

- Es un valor est√°ndar en tareas de **voz** y audio en general.  
- Coeficientes adicionales (14, 15, ‚Ä¶) capturan detalles muy finos que pueden ser m√°s **ruido** que informaci√≥n √∫til.  
- Aumentar dimensionalidad sin suficiente cantidad de datos incrementa el riesgo de **sobreajuste**.

El primer coeficiente (`mfcc_1_mean`) est√° fuertemente asociado con la **energ√≠a global** del espectro (similar a un log-energ√≠a). Los coeficientes superiores describen la forma del espectro y su ‚Äútextura‚Äù.

Para usar este CSV en modelos supervisados, faltar√≠a:

- Enriquecerlo con **etiquetas de clase** y metadatos (fold, id de la grabaci√≥n).  
- Aplicar un escalado tipo **StandardScaler** para que todas las columnas tengan media 0 y varianza 1, evitando que los MFCCs de gran magnitud dominen sobre ZCR o RMS.

---

### 5. Exploraciones avanzadas

#### 5.1 M√©tricas espectrales din√°micas

Se calcularon y graficaron tres m√©tricas a lo largo del tiempo:

- **Spectral Centroid** (centroide, ‚Äúbrillo‚Äù del sonido).  
- **Spectral Rolloff (0.85)**, frecuencia por debajo de la cual se acumula el 85% de la energ√≠a.  
- **Spectral Bandwidth**, ancho de banda espectral.

![M√©tricas espectrales din√°micas](../assets/14-spectral-metrics.png){ width="900" }  
*Fig. 8 ‚Äî Evoluci√≥n temporal de centroid, rolloff y bandwidth. Las zonas con energ√≠a m√°s brillante y compleja muestran picos en estas curvas, especialmente en el tramo final del clip.*

Estas curvas ayudan a entender c√≥mo cambia el contenido espectral a lo largo del tiempo y podr√≠an servir como features agregadas adicionales.

#### 5.2 Distribuci√≥n de audios por fold

Se calcul√≥ la cantidad de clips por fold (carpeta padre de cada archivo):

![Cantidad de audios por fold](../assets/14-fold-counts.png){ width="800" }  
*Fig. 9 ‚Äî Recuento de audios por fold de UrbanSound8K: la distribuci√≥n es bastante equilibrada, con valores entre ~800 y ~990 clips por fold.*

Esto confirma que UrbanSound8K fue construido con folds relativamente balanceados, √∫til para validaci√≥n cruzada.

#### 5.3 Data augmentation: pitch shift y time stretch

Como exploraci√≥n de **augmentations** se aplicaron:

- **Pitch shift +2 semitonos** sobre el audio estandarizado.  
- **Time stretch 0.9√ó** (audio levemente m√°s lento).

Se volvieron a generar espectrogramas para observar los cambios:

![Pitch shift +2 semitonos](../assets/14-spec-pitchshift.png){ width="900" }  
*Fig. 10 ‚Äî Espectrograma con pitch shift de +2 semitonos: las bandas de energ√≠a se desplazan hacia frecuencias algo m√°s altas, manteniendo la estructura temporal.*

![Time stretch 0.9x](../assets/14-spec-timestretch.png){ width="900" }  
*Fig. 11 ‚Äî Espectrograma tras time stretch 0.9√ó: el patr√≥n temporal se estira, alargando levemente la duraci√≥n efectiva del evento sin modificar demasiado el contenido frecuencial.*

Estas transformaciones son √∫tiles para aumentar la diversidad del dataset sin cambiar la etiqueta de la clase.

---

## Evidencias

- [Notebook completo](../recursos_files/14-audio.ipynb)

---

## Reflexi√≥n

- **Est√°ndar de entrada:**  
  El pipeline final dej√≥ todos los audios en **16 kHz**, **3 s**, mono y amplitud normalizada. Esto simplifica enormemente el entrenamiento, reduce tama√±o y asegura coherencia entre muestras.

- **Paso que m√°s mejor√≥ la calidad perceptual:**  
  El **recorte de silencios** (`trim`) fue el cambio m√°s positivo: elimina porciones sin informaci√≥n √∫til y ruido de fondo de muy baja energ√≠a, aumentando la relaci√≥n se√±al-ruido efectiva sin distorsionar la parte importante del audio.

- **Ruido en el espectrograma:**  
  El **ruido blanco** agregado se aprecia como energ√≠a uniforme en casi todo el espectro, sin patrones claros. Es una buena referencia para entender c√≥mo se ve una se√±al ruidosa en comparaci√≥n con el patr√≥n estructurado del evento sonoro.

- **Checks autom√°ticos propuestos para QA:**  
  - SNR aproximado > **15 dB**.  
  - Duraci√≥n efectiva del clip ‚àà [2.5 s, 3.5 s].  
  - `max(|amplitud|) ‚â§ 1.0` para evitar clipping.  
  - N√∫mero de frames MFCC > cierto m√≠nimo (por ejemplo, 30) para asegurar resoluci√≥n temporal.  
  - Centroid y ZCR dentro de rangos razonables (evitar clips casi silenciosos o puramente ruido).  
  Estos checks funcionar√≠an como un ‚Äúsem√°foro‚Äù de preprocesamiento antes de lanzar el entrenamiento.

---

## Conclusiones

- Se defini√≥ y aplic√≥ un **pipeline consistente** de preprocesamiento de audio (mono, 16 kHz, 3 s, normalizado) sobre UrbanSound8K.
- Los **espectrogramas STFT y de Mel** permiten visualizar claramente d√≥nde est√°n los eventos sonoros y c√≥mo se distribuye la energ√≠a en frecuencia.
- La experimentaci√≥n con **ruido blanco** y un filtro **high-pass** mostr√≥ c√≥mo limpiar ruidos de baja frecuencia sin perder contenido √∫til.
- Se extrajeron **MFCCs y m√©tricas de energ√≠a** para 100 audios, generando un CSV de 31 columnas adecuado para modelos de ML.
- Las exploraciones avanzadas (m√©tricas espectrales din√°micas, an√°lisis de folds y augmentations) reforzaron la idea de que el preprocesamiento de audio no solo limpia datos, sino que tambi√©n dise√±a **representaciones m√°s informativas** para el aprendizaje supervisado.

---

## Referencias

- Documentaci√≥n de librosa:  
  - [librosa.core.load](https://librosa.org/doc/latest/generated/librosa.load.html)  
  - [librosa.display.specshow](https://librosa.org/doc/latest/generated/librosa.display.specshow.html)  
  - [librosa.feature.mfcc](https://librosa.org/doc/latest/generated/librosa.feature.mfcc.html)  
  - [librosa.effects.trim](https://librosa.org/doc/latest/generated/librosa.effects.trim.html)  
  - [librosa.effects.time_stretch](https://librosa.org/doc/latest/generated/librosa.effects.time_stretch.html)  
  - [librosa.effects.pitch_shift](https://librosa.org/doc/latest/generated/librosa.effects.pitch_shift.html)  

- Dataset:  
  - [UrbanSound8K (Kaggle)](https://www.kaggle.com/datasets/chrisfilo/urbansound8k)

- Procesamiento de se√±ales:  
  - [scipy.signal.butter](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html)  
  - [scipy.signal.lfilter](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.lfilter.html)
