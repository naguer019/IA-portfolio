---
title: "üîÅ Del C√≥digo al Flujo: C√≥mo Prefect Reinventa el ETL Moderno"
date: 2025-12-05
---

# üîÅ Del C√≥digo al Flujo: C√≥mo Prefect Reinventa el ETL Moderno

## Contexto

En esta actividad se trabaj√≥ con **Prefect**, una herramienta moderna de orquestaci√≥n de pipelines de datos, dise√±ando e implementando un mini pipeline ETL completo.
El objetivo fue investigar la documentaci√≥n oficial para comprender los conceptos fundamentales (**Tasks, Flows, DAGs impl√≠citos, caching**) y explorar funcionalidades avanzadas como **retries, logging estructurado, validaci√≥n de datos y deployments**.

A partir de esto, se construy√≥ un pipeline ETL para procesar datos de ventas de un e-commerce, aplicando principios de **DataOps** como observabilidad, reproducibilidad y CI/CD para datos.

**Fuente**: [Tarea 14 (15 en la p√°gina) - Prefect](https://juanfkurucz.com/ucu-id/ut5/15-etl-dataops-prefect/)

---

## Objetivos

* Comprender los conceptos fundamentales de Prefect: **Tasks, Flows, estados y caching**.
* Investigar y aplicar funcionalidades avanzadas: **retries, logging estructurado, validaci√≥n**.
* Dise√±ar e implementar un **pipeline ETL completo** con Prefect.
* Explorar **deployments y scheduling** para ejecuci√≥n programada.
* Conectar Prefect con principios de **DataOps**: observabilidad, reproducibilidad, CI/CD.
* Comparar Prefect con alternativas como **Apache Airflow** y **Dagster**.

---

## Actividades (con tiempos estimados)

| Actividad                                | Tiempo | Resultado esperado                                           |
| ---------------------------------------- | :----: | ------------------------------------------------------------ |
| Investigaci√≥n: Conceptos fundamentales   |   15m  | Respuestas sobre Tasks, Flows, Results y Caching             |
| Dise√±o conceptual del escenario          |   5m   | Escenario definido: e-commerce con roles identificados       |
| Implementaci√≥n del pipeline base         |   20m  | Pipeline ETL funcionando: extract, transform, load           |
| Investigaci√≥n: Funcionalidades avanzadas |   15m  | Retries, caching, logging, concurrencia investigados         |
| Investigaci√≥n: Deployments y Scheduling  |   10m  | Conceptos de deployment, work pools, scheduling comprendidos |
| Extensi√≥n DataOps                        |   15m  | Validaci√≥n con logging estructurado implementada             |
| Reflexi√≥n y conexi√≥n con DataOps         |   5m   | Reflexiones sobre observabilidad, reproducibilidad y CI/CD   |

---

## Desarrollo

### 1. Investigaci√≥n: Conceptos Fundamentales de Prefect

#### 1.1 Tasks en Prefect

**¬øQu√© es una Task?**
Una Task en Prefect es una unidad de trabajo individual que representa una operaci√≥n espec√≠fica dentro de un pipeline.
Seg√∫n la [documentaci√≥n oficial](https://docs.prefect.io/latest/concepts/tasks/), una task es *‚Äúa discrete piece of work that can be tracked and retried independently‚Äù*.
En la pr√°ctica, son funciones Python decoradas con `@task` que encapsulan l√≥gica concreta (extraer datos, transformar, cargar, validar, etc.).

**Evaluaci√≥n diferida ("lazy evaluation")**
Las tasks no se ejecutan inmediatamente cuando se definen o llaman. Prefect primero construye una representaci√≥n del grafo de dependencias y la ejecuci√≥n real ocurre al correr el **flow** completo.
Esto permite:

* Optimizar la ejecuci√≥n.
* Resolver dependencias de forma autom√°tica.
* Manejar DAGs complejos sin tener que declararlos manualmente.

**Estados de las Tasks**
Prefect rastrea el estado de cada task durante todo su ciclo de vida:

* `PENDING`: Esperando ejecuci√≥n.
* `RUNNING`: En ejecuci√≥n.
* `COMPLETED`: Finalizada con √©xito.
* `FAILED`: Fall√≥ durante la ejecuci√≥n.
* `RETRYING`: Reintentando despu√©s de un fallo.
* `CANCELLED`: Cancelada antes de terminar.
* `CRASHED`: Fallo inesperado (error no controlado).

Esto permite tener **observabilidad fina** sobre qu√© pas√≥ en cada paso del pipeline.

**Par√°metros importantes del decorador `@task`**

* `retries`: N√∫mero de reintentos si falla.
* `retry_delay_seconds`: Tiempo entre reintentos.
* `timeout_seconds`: Tiempo m√°ximo de ejecuci√≥n.
* `cache_key_fn`: Funci√≥n personalizada para generar la clave de cach√©.
* `cache_expiration`: Duraci√≥n de validez del cach√©.
* `tags`: Etiquetas para organizaci√≥n y filtrado.
* `log_prints`: Captura autom√°tica de `print` como logs estructurados.

---

#### 1.2 Flows en Prefect

**Diferencias entre Flow y Task**

* Una **Task** es una unidad de trabajo puntual.
* Un **Flow** es el *contenedor* que orquesta y coordina la ejecuci√≥n de m√∫ltiples tasks, definiendo un flujo de trabajo completo.

Necesitamos ambos porque:

* Las **Tasks** permiten modularizar y reutilizar l√≥gica.
* El **Flow** se encarga de las dependencias y de la orquestaci√≥n global.

**Subflows**
Un **subflow** es un Flow que se llama desde otro Flow, √∫til para:

* Modularidad.
* Reutilizaci√≥n de partes del pipeline.
* Testing m√°s simple.
* Separaci√≥n l√≥gica en subprocesos (por ejemplo, `extract_and_validate()` como subflow reutilizable).

**DAGs impl√≠citos**
En Prefect, el DAG no se declara de forma expl√≠cita como en Airflow.
Cuando se pasa el resultado de una task como par√°metro a otra (`t2(t1())`), Prefect detecta la dependencia y construye **el DAG de manera impl√≠cita**, definiendo el orden correcto de ejecuci√≥n.

---

#### 1.3 Results y Caching

**Result persistence**
Prefect puede guardar y recuperar resultados de tasks. Esto es importante porque:

* Evita re-ejecutar tasks costosas.
* Facilita el debugging (se pueden inspeccionar resultados intermedios).
* Mejora la resiliencia (si falla algo, no hay que recomputar todo).
* Ayuda a la reproducibilidad y auditor√≠a.

**Caching**
Permite evitar re-ejecuciones cuando las entradas no cambiaron. Se puede configurar:

* Usando una clave de cach√© autom√°ticamente generada por Prefect a partir de los par√°metros.
* Definiendo `cache_expiration` (por cu√°nto tiempo es v√°lido el resultado).
* Personalizando la clave con `cache_key_fn`.

**`cache_key_fn`**
Sirve para:

* Cachear en funci√≥n de solo algunos par√°metros.
* Implementar l√≥gica de invalidaci√≥n de cach√© basada en reglas de negocio (por ejemplo, fecha de actualizaci√≥n de una tabla).

---

### 2. Dise√±o Conceptual

**Escenario elegido**:
Ventas de un e-commerce con datos de transacciones diarias.

**Roles y arquitectura del escenario:**

* **Business Data Owner**: Equipo de ventas/negocios que genera las transacciones.
* **Data Engineers**: Construyen y mantienen el pipeline ETL.
* **Data Consumers**: Analistas, cient√≠ficos de datos y dashboards que consumen los datos procesados.

**Tipo de pipeline**: **Batch**

**Justificaci√≥n**:

* Las ventas se procesan en lotes diarios.
* No se requiere tiempo real para el caso inicial.
* El batch es eficiente para an√°lisis agregados y facilita:

  * validaci√≥n,
  * control de errores,
  * auditor√≠a de cada corrida.

---

### 3. Implementaci√≥n del Pipeline Base

#### 3.1 Setup

Se configur√≥ el entorno con:

* `prefect` (para flows y tasks)
* `pandas`, `numpy`
* `datetime` y utilidades est√°ndar de Python

Imports clave:

```python
from prefect import flow, task
import pandas as pd
import numpy as np
from datetime import datetime
```

---

#### 3.2 Tasks Implementadas

**Task 1: Extract ‚Äî `extract_data`**

* Decorador: `@task(tags=["extract", "data-source"], log_prints=True)`
* Funci√≥n: simula extracci√≥n de datos de ventas generando 100 registros con:

  * fecha,
  * producto,
  * cantidad,
  * precio_unitario,
  * regi√≥n.
* Uso de tags para organizaci√≥n y `log_prints=True` para registrar mensajes.

**Task 2: Transform ‚Äî `transform_data`**

* Decorador: `@task(tags=["transform", "data-processing"], log_prints=True)`
* Transformaciones principales:

  * C√°lculo de `total = cantidad * precio_unitario`.
  * Categorizaci√≥n de `total` en bandas de ticket (Bajo, Medio, Alto, Muy Alto).
  * Agregado de columnas de **mes** y **d√≠a de la semana** para an√°lisis temporal.

**Task 3: Load ‚Äî `load_data`**

* Decorador: `@task(tags=["load", "data-output"], log_prints=True, retries=2, retry_delay_seconds=3)`
* Funci√≥n: guarda los datos transformados en un archivo CSV.
* Incluye **reintentos autom√°ticos** en caso de fallo de escritura (I/O).

---

#### 3.3 Flow Principal

**Flow: `etl_flow()`**

* Decorador: `@flow(name="ETL Pipeline Ventas", log_prints=True)`
* Pasos:

  1. `df_raw = extract_data()`
  2. `df_transformed = transform_data(df_raw)`
  3. `load_data(df_transformed)`

Prefect construye autom√°ticamente el DAG:

`extract_data ‚Üí transform_data ‚Üí load_data`

Esto muestra en la pr√°ctica c√≥mo las dependencias se definen *por el flujo de datos* y no por declaraciones expl√≠citas.

---

### 4. Investigaci√≥n: Funcionalidades Avanzadas

#### 4.1 Retries y manejo de errores

Usando `@task(retries=N, retry_delay_seconds=X)` se pueden configurar reintentos autom√°ticos para tareas que fallan espor√°dicamente (APIs, conexiones, escritura en disco, etc.).
En el pipeline, `load_data()` utiliza 2 reintentos con 3 segundos de espera.

---

#### 4.2 Caching de resultados

Permite evitar re-ejecutar tasks costosas cuando los par√°metros de entrada no cambiaron.
Se configura con:

* `cache_expiration` (ej: `timedelta(hours=1)`).
* `cache_key_fn` para personalizar la clave de cach√©.

Es especialmente √∫til para:

* Extracciones de APIs.
* C√°lculos pesados.
* Etapas intermedias costosas de un pipeline.

---

#### 4.3 Logging personalizado

Se puede usar:

* `get_run_logger()` para logs estructurados.
* `log_prints=True` para capturar `print()` autom√°ticamente.

Ventajas:

* Logs centralizados.
* Integraci√≥n con la UI de Prefect.
* Facilita diagn√≥stico y auditor√≠a en DataOps.

---

#### 4.4 Concurrencia y paralelismo

Prefect soporta ejecuci√≥n concurrente con `ConcurrentTaskRunner()` en el flow.
Las tasks independientes se pueden ejecutar en paralelo usando `.submit()`.

Ejemplo conceptual:

* Procesar una task `transform_region(region)` para cada regi√≥n en paralelo.
* Reducir el tiempo total de una corrida batch.

---

### 5. Investigaci√≥n: Deployments y Scheduling

#### 5.1 Conceptos de Deployment

**Deployment**
Es la configuraci√≥n que permite ejecutar un Flow de manera programada o bajo demanda. Conecta:

* el c√≥digo del Flow
* con la configuraci√≥n de ejecuci√≥n (scheduling, work pool, par√°metros).

Mientras que el **Flow** es el c√≥digo Python, el **Deployment** es la ‚Äúinstalaci√≥n‚Äù del Flow en Prefect, con metadatos de ejecuci√≥n.

**Work Pool**

* Grupo de recursos/entornos donde se ejecutan los flows.
* Permite organizar ejecuciones en distintos entornos (local, servidor, cloud).

**Worker**

* Proceso que se conecta a un Work Pool y toma trabajos (flows) para ejecutarlos.
* La cadena es: `Deployment ‚Üí Work Pool ‚Üí Worker ‚Üí Ejecuci√≥n del Flow`.

---

#### 5.2 Scheduling

**Tipos de schedules** m√°s comunes:

* `CronSchedule`: usando sintaxis cron (`"0 6 * * *"` ‚Üí todos los d√≠as a las 6:00).
* `IntervalSchedule`: ejecuci√≥n cada cierto intervalo (`timedelta(hours=1)`).
* `RRuleSchedule`: reglas m√°s complejas (RFC 5545), √∫til para calendarios de negocio.

**Ejemplo cron**
`"0 6 * * *"` ‚Üí todos los d√≠as a las 6 AM.
Formato: `minuto hora d√≠a_mes mes d√≠a_semana`.

**RRuleSchedule**
M√°s flexible, permite definir patrones como ‚Äúlunes y mi√©rcoles a las 9 AM, excepto feriados‚Äù.

---

### 6. Extensi√≥n DataOps: Validaci√≥n con Logging Estructurado

Se implement√≥ la **Opci√≥n A ‚Äì Validaci√≥n con logging estructurado**, clave para DataOps.

**Task de validaci√≥n: `validate_data()`**

* Decorador:
  `@task(retries=1, retry_delay_seconds=2, tags=["validation", "data-quality"], log_prints=True)`
* Usa `get_run_logger()` para registrar mensajes de validaci√≥n.

**Validaciones realizadas:**

1. **DataFrame no vac√≠o**.
2. **Valores nulos**: se registran como *warning*.
3. **Columnas requeridas** (`fecha`, `producto`, `cantidad`, `precio_unitario`, `total`).
4. **Tipos de datos correctos** (ej: `total` num√©rico).
5. **Valores negativos** en `cantidad` detectados como *warning*.

**Niveles de log:**

* `info`: validaciones exitosas e informaci√≥n general.
* `warning`: problemas no cr√≠ticos (nulos, valores at√≠picos).
* `error`: problemas cr√≠ticos que deben detener el pipeline.

El flow actualizado (`etl_flow_with_validation()`) ejecuta la validaci√≥n **entre extracci√≥n y transformaci√≥n**, asegurando que solo se procese informaci√≥n de calidad.

---

### 7. Reflexi√≥n y Conexi√≥n con DataOps

#### 7.1 Prefect y principios de DataOps

**Observabilidad**

Prefect ofrece observabilidad a trav√©s de:

* Estados detallados por task y por flow.
* Logs estructurados centralizados.
* M√©tricas de tiempo, tasas de √©xito/fallo.
* UI con monitoreo en tiempo real.
* Posibilidad de alertas y notificaciones.

**Reproducibilidad**

* El caching y la persistencia de resultados ayudan a obtener resultados consistentes.
* Se pueden comparar outputs actuales con resultados previos cacheados.
* Facilita reproducir corridas anteriores para auditor√≠a.

**CI/CD para datos**

* Los Deployments permiten versionar y desplegar flows.
* Los schedules automatizan ejecuciones recurrentes.
* Es posible tener distintos ambientes (dev / staging / prod).
* Se integra con pipelines de CI/CD (por ejemplo, GitHub Actions, GitLab CI).

---

#### 7.2 Comparaci√≥n con Alternativas

**Prefect vs Apache Airflow**

1. **Filosof√≠a de dise√±o**

   * Airflow usa DAGs expl√≠citos y *operators*.
   * Prefect usa DAGs impl√≠citos con c√≥digo Python m√°s natural.

2. **Curva de aprendizaje**

   * Prefect es m√°s directo: solo decoradores `@task` y `@flow`.
   * Airflow requiere entender DAGs, Operators, XComs, etc.

3. **Experiencia de desarrollo**

   * Prefect es m√°s ‚ÄúPythonic‚Äù y menos verboso.
   * Airflow sigue muy presente en entornos legacy y Big Data cl√°sicos.

**Prefect vs Dagster**

* **Enfoque**

  * Dagster es m√°s *data-centric* (assets como primitivos principales).
  * Prefect es m√°s *workflow-centric* (tasks y flows).

* **Integraci√≥n**

  * Dagster integra fuerte con ecosistema de datos (pandas, Spark, etc.).
  * Prefect tiene un ecosistema m√°s amplio y una comunidad mayor hoy en d√≠a.

Ambas son alternativas modernas a Airflow; la elecci√≥n depende de si el equipo piensa m√°s en t√©rminos de **datos** (Dagster) o de **flujos de trabajo** (Prefect).

---

## Evidencias

* Notebook de implementaci√≥n: `docs/portfolio/UT5/Notebooks/quince.ipynb`.
* Pipeline ETL completo funcionando con Prefect.
* Task de validaci√≥n con **logging estructurado** integrada en el flow.
* Respuestas de investigaci√≥n basadas en documentaci√≥n oficial de Prefect.

---

## Resultados

En esta actividad se logr√≥:

1. Implementar un **pipeline ETL completo** para un escenario de e-commerce.
2. Investigar y aplicar funcionalidades avanzadas de Prefect (retries, caching, logging, deployments).
3. Incorporar una **extensi√≥n DataOps** con validaci√≥n y logging estructurado.
4. Conectar Prefect con principios de **observabilidad, reproducibilidad y CI/CD de datos**.
5. Comparar Prefect con herramientas alternativas (Airflow, Dagster) entendiendo su rol en el ecosistema.

---

## Aprendizajes Clave

### Conceptos fundamentales

* Diferenciar entre **Task** (unidad de trabajo) y **Flow** (orquestaci√≥n).
* Entender c√≥mo Prefect construye **DAGs impl√≠citos** a partir de dependencias de datos.
* Ver el valor de los **estados de ejecuci√≥n** y del logging para observabilidad.

### Funcionalidades avanzadas

* Los **retries** permiten robustecer el pipeline frente a errores intermitentes.
* El **logging estructurado** facilita much√≠simo el debugging en escenarios reales.
* El **caching** apunta tanto a eficiencia como a reproducibilidad.

### DataOps

* Prefect habilita pr√°cticas de DataOps al ofrecer:

  * observabilidad,
  * versionado,
  * programaci√≥n recurrente,
  * integraci√≥n con CI/CD.

---

## Desaf√≠os y Soluciones

### Desaf√≠o 1: Entender DAGs impl√≠citos

**Problema**: al principio cuesta entender c√≥mo se construye el DAG sin declararlo.
**Soluci√≥n**: experimentar pasando resultados de una task a otra y observar en la UI de Prefect la estructura generada.

---

### Desaf√≠o 2: Dise√±o de validaciones √∫tiles

**Problema**: encontrar el equilibrio entre demasiadas validaciones (ruido) y pocas (falta de control).
**Soluci√≥n**: usar diferentes niveles de logging (`info`, `warning`, `error`) y centrarse primero en columnas clave y tipos de datos cr√≠ticos.

---

### Desaf√≠o 3: Diferenciar Flows de Deployments

**Problema**: confusi√≥n inicial entre el c√≥digo del flow y su configuraci√≥n de ejecuci√≥n.
**Soluci√≥n**: pensar el **Flow** como el *c√≥digo Python* y el **Deployment** como la *configuraci√≥n de ‚Äúc√≥mo, cu√°ndo y d√≥nde‚Äù se ejecuta*.

---

## Decisiones y Pr√≥ximos Pasos

### Decisiones tomadas

1. Usar un **escenario de e-commerce** simple pero realista.
2. Empezar con pipeline **batch diario** en lugar de streaming.
3. Elegir la extensi√≥n DataOps de **validaci√≥n con logging** por ser m√°s cr√≠tica para calidad de datos que la concurrencia en este primer ejemplo.
4. Registrar logs estructurados en todas las tasks para maximizar observabilidad.

### Pr√≥ximos pasos

* Probar Prefect en entorno **Cloud/Server**.
* Ampliar el set de validaciones con herramientas dedicadas (Great Expectations, Pydantic).
* Implementar **concurrencia por regi√≥n** o por fuente de datos.
* Definir un **Deployment real** con scheduling (por ejemplo, diario 06:00).
* Integrar el pipeline con CI/CD (GitHub Actions u otro).
* Configurar persistencia de resultados en almacenamiento externo (S3, GCS).
* A√±adir alertas ante fallos o degradaci√≥n de calidad de datos.

---

> *"La mejor forma de aprender una herramienta es leer su documentaci√≥n oficial.
> Los tutoriales te dan el 'qu√©'; la documentaci√≥n, el 'por qu√©' y el 'c√≥mo'."*

---

## Referencias

* [Documentaci√≥n oficial de Prefect](https://docs.prefect.io/)
* [Prefect Concepts Overview](https://docs.prefect.io/latest/concepts/)
* [Prefect Tasks](https://docs.prefect.io/latest/concepts/tasks/)
* [Prefect Flows](https://docs.prefect.io/latest/concepts/flows/)
* [Prefect Caching](https://docs.prefect.io/latest/concepts/tasks/#caching)
* [Prefect Deployments](https://docs.prefect.io/latest/concepts/deployments/)
